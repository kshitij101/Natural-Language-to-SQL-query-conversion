{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np               #for maths\n",
    "import pandas as pd              #for data manipulation\n",
    "import matplotlib.pyplot as plt  #for visualization\n",
    "import json\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:\\\\Kshitij\\\\DEV\\\\Datasets\\\\spider\\\\train_spider.json\"\n",
    "# data_Set = open(\"C:\\\\Kshitij\\\\DEV\\\\Datasets\\\\spider\\\\train_others.json\")\n",
    "queries =[]\n",
    "questions = []\n",
    "with open(filename, 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "for i in range(len(datastore)):\n",
    "\tqueries.append(datastore[i]['query'])\n",
    "\tquestions.append(datastore[i]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(queries).reshape(-1,1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store the transform data\n",
    "transform_data = np.copy(data)\n",
    "\n",
    "#find the max length name\n",
    "max_length = 0\n",
    "for index in range(len(data)):\n",
    "    max_length = max(max_length,len(data[index,0]))\n",
    "\n",
    "#make every name of max length by adding '.'\n",
    "for index in range(len(data)):\n",
    "    length = (max_length - len(data[index,0]))\n",
    "    string = '.'*length\n",
    "    transform_data[index,0] = ''.join([transform_data[index,0],string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "[['SELECT name ,  born_state ,  age FROM head ORDER BY age..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................']\n",
      " ['SELECT creation ,  name ,  budget_in_billions FROM department....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................']\n",
      " ['SELECT max(budget_in_billions) ,  min(budget_in_billions) FROM department........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................']\n",
      " ['SELECT avg(num_employees) FROM department WHERE ranking BETWEEN 10 AND 15........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................']\n",
      " [\"SELECT name FROM head WHERE born_state != 'California'...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\"]\n",
      " [\"SELECT DISTINCT T1.creation FROM department AS T1 JOIN management AS T2 ON T1.department_id  =  T2.department_id JOIN head AS T3 ON T2.head_id  =  T3.head_id WHERE T3.born_state  =  'Alabama'..................................................................................................................................................................................................................................................................................................................................................................................................\"]\n",
      " ['SELECT born_state FROM head GROUP BY born_state HAVING count(*)  >=  3...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................']\n",
      " ['SELECT creation FROM department GROUP BY creation ORDER BY count(*) DESC LIMIT 1.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................']\n",
      " [\"SELECT T1.name ,  T1.num_employees FROM department AS T1 JOIN management AS T2 ON T1.department_id  =  T2.department_id WHERE T2.temporary_acting  =  'Yes'......................................................................................................................................................................................................................................................................................................................................................................................................................................\"]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed Data\")\n",
    "print(transform_data[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(rgx_list, text):\n",
    "#     new_text = text\n",
    "#     for rgx_match in rgx_list:\n",
    "#         new_text = re.sub(rgx_match, '', new_text)\n",
    "#     return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 3090\n",
      "Vocab      = {'Restaurant', 'Crew', \"'Elsa\", 'Assets', 'Davis', 'Lewis', 'Bookings', 'loan', 'NEB', 'Customer_Master_Index', 'Dinning', 'Jones', 'name_first', 'Number_Deaths', 'date_in_location_from', 'player_coach', 'Customer_id', 'Num_of_Factories', 'mission', 'Credits', 'Shieber', 'document_type_description', 'amount', 'Employees.role_code', 'Kids', 'account_details', 'company_id', 'booking_id', 'Scientists', 'farm_competition', 'GORDON', 'Maryland', 'start_station_name', 'Film_ID', 'hoursperweek', 'quality_rank', 'date_in_locaton_to', 'compatible_since_year', 'Lucas', 'claims_processing_stages', 'service_details', 'catalog_level_name', \"'mid\", \"'Sandwich\", 'product_size', \"'Regular\", 'Massif', 'Movies', 'genre_is', 'player_api_id', 'Kenton', 'Beach', 'Hosts', 'Karson', 'Drama', 'artwork', \"'John\", 'amount_of_transaction', 'wrau', \"'Orbit\", 'membership_amount', 'YEAR', 'New', 'Info', 'PrimaryAffiliation', 'District_name', 'Issue_Date', 'parties', 'Airport_Name', 'Cash', 'Total', \"'Glasgow\", 'airlines', 'available_yn', 'ype_Of_Restaurant', 'dept_address', 'document_structure_code', 'product_type_code', 'Liberal', 'Square', \"'Marriage\", 'track_id', 'detention_type_description', 'trust', 'ROLES', \"'Good\", 'payment_method_code', \"'Patent\", 'budget_million', 'Circulation_History.draft_number', 'max_salary', 'user_name', 'color_code', 'Oct', \"'Waterbury\", 'musical', 'rank', 'Visit_Date', 'match_id', 'Nominee', 'teacher_id', 'transaction_id', 'stu_num', 'ORDER', \"'MK_MAN\", 'date_valid_from', 'market', 'allergytype', 'urcotte', 'driverid', 'Koby', 'vehicle_id', 'rack', 'theme', 'acc_bal', 'enroll_grade', 'Government', 'Crime_rate', \"'--\", 'guest_last_name', 'college_id', 'Homenick', 'Carrier', 'Model_name', 'Gymnast_ID', 'camera_lens_id', 'Napa', 'party_host', 'unit_price', 'speed', 'incident_type_description', 'ship_id', 'class_code', \"'Noel\", 'Moulin', 'EMP_DOB', 'volume', 'Marianne', 'duration', \"'Thiago\", \"'Cutter\", 'Unbound', 'Stuid', 'John', 'Led', 'Official_Name', 'grant_end_date', 'area', 'order_status_code', 'collection', 'Wing', 'Vivian', 'population', 'num_of_component', 'Headquarters', 'airport', 'MEMBER_OF', 'appointment', 'gdp', 'City_ID', 'statistics', 'Village', 'weather', 'Art', 'Green', 'Computing', 'Domestic_Passengers', 'overall_rating', 'EMP_FNAME', 'campus', 'Member', 'Official_native_language', 'Australian', 'Cleavant', 'low_temperature', 'Invoice', 'hall_of_fame', 'Annual_entry_exit', 'date_became_customer', 'part_id', 'building_short_name', 'match_season', 'student_course_attendance', 'Customers_Cards', 'Medhurst', 'dribbling', 'train_number', 'main_services', 'undergoes', 'Speed', 'Shipped', 'flax', 'building_phone', 'country_name', 'Functional', 'Bosco', 'Languages', 'instructor', 'document_type_code', 'problems', 'job_id', 'bank', 'Height', 'Andaman', 'treatment', 'OWNER', 'fault_log_entry_datetime', 'DNO', 'head_id', 'max_dew_point_f', 'name_full', 'onnage', 'Grape', 'Suite', 'CUSTOMER', 'medicine_enzyme_interaction', \"'James\", 'Live', 'online', 'MOYER', 'class_room', \"'Alabama\", 'papers', 'yearid', 'Accounting', 'museum', 'time_of_day', 'songs', 'machine_id', 'parking_fines', 'Baltimore', 'dorm_amenity', 'maintenance_contract_company_id', 'person', 'event_name', 'organizations', 'support_rate', 'team_id_winner', 'professor', 'tracks', 'CONRAD', 'Party_Theme', \"'Chandler\", \"'Catering\", 'english', 'county_ID', 'media_types', 'Type', 'product_description', 'PHOTOS', 'Host_City', 'Apartment_Bookings', 'Electoral_Register', 'RANSACTIONS', 'Ref_Service_Types', 'ACCT-1', 'order_item_id', 'left', 'Brenden', 'Name', 'UCLA', 'wine', 'Catalogs', 'Chinese', 'Draft_Pick_Number', 'Grand', 'blockcode', 'location_description', 'residents', 'room_count', 'Centre', 'mID', 'product_category_description', 'address_line_2', 'GameID', 'transaction_amount', 'zip_postcode', 'Oil', 'Paper', 'Bridge', 'text', 'Enterprises', 'Faculty_participates_in', 'Pennsylvania', 'range', 'SportsInfo', 'FTE_AY', 'Ashley', 'airport_id', 'Mall', 'game1', 'Market_Details', 'Herbs', 'Major', 'Chocolate', 'profits_billion', 'EMP_LNAME', 'Orange', 'Jiangsu', 'WINE', 'Sex', 'blues', 'engineer_id', 'Pass', 'MEDIATYPE', 'competition_type', 'claim_outcome_code', 'Money_Requested', 'state_province', 'Nicholas', 'composer', 'year_join', \"'Night\", 'branch', 'dock_count', 'Group', 'Royal_Family_ID', 'birthday', 'Calgary', 'Faculty', 'price_range', 'source_system_code', 'orange', 'Volume_ID', 'GROUP', 'src_apid', 'participants_in_Events', 'Staff', 'booked_amount', 'King', 'room_number', 'LastName', 'crs_code', 'BOOKINGS', 'Country_id', 'Year_Join', 'eam_id', 'Theme', 'Marketing_Region_Name', 'booking_end_date', 'Status_Code', 'Bar', \"'Cutlery\", 'roomname', \"'Tournament\", 'employee', \"'Computer\", 'park_id', 'lettergrade', 'international', 'application', 'rooms', 'party_phone', 'statement_id', 'Google', 'Fosse', 'Catalog_Contents_Additional_Attributes', 'asks', 'Residents_Services', \"'Rainbow\", 'policy_type_code', 'Science', 'school_bus', 'Type_of_Thing_Code', 'prof_num', 'PERFORMERS', 'President_Vote', 'order_id', 'Spielberg', 'log_entry_description', 'Student', 'ournament', 'College_Location', 'Phone_id', 'back', 'Ref_Document_Types', 'color_description', 'Meaghan', 'Feliciaberg', 'England', 'NYY', 'with', 'employee_Name', 'Daan', 'driverstandings', 'city_code', 'Rank', 'constructorStandings', \"'Texas\", 'Program', 'team_name', 'Score', 'Ryley', 'share_count', 'event', 'Company_ID', \"'Protoporphyrinogen\", 'ype_Of_Restaurant.ResID', 'Airport_ID', 'Event_ID', 'Participant_ID', 'Marketing_Region_Code', 'born_state', 'constructors', 'gymnast', 'resolution', 'Apple', \"'Check\", 'Museum_ID', 'address_content', 'Volume', 'locations', 'Balls', 'you', 'incorporated_in', 'FACULTY', 'Journal_ID', 'prof_office', 'other_hotel_details', 'Investor', \"'Kayaking\", 'calendar_date', 'Description', 'staff_gender', 'All_Games', 'building_description', 'Delivery_Route_Locations', 'end_station_id', 'read', 'Billy', 'Mary', 'Conglomerate', 'Winery', 'individual_id', 'Clean_Jerk', \"'Chennai\", 'sportname', 'State', 'salary', 'document_id', 'crs_description', 'Host_city_ID', 'staff', 'Competition_type', 'status', 'shipment_date', 'booking_status_code', \"'Paid\", 'gender_mf', \"'Panama\", 'Parkway', 'Lysanne', 'Fog', 'Features', 'NABOZNY', 'outcome_code', \"'Alice\", 'Oxford', 'Amount_Settled', 'Rogers', 'Parts', 'nomination', 'department_store_chain', 'open_date', 'ssn', 'City', 'Rooms', 'Wind', 'Red', 'aircraft', 'albums', 'Character', 'Banking', 'functional_areas', 'Meyer', 'category_id', 'ArtistID', \"'Toubkal\", 'Hall', 'Puzzling', 'affiliated_with', 'service_name', 'model_name', \"'Len\", 'actor_id', 'date_valid_to', 'attribute_data_type', 'bridge', 'destination', 'Robin', 'food', 'AAC', 'Dr.', 'Stories', \"'Louisville\", 'Service_ID', \"'International\", 'eam', 'Fast', 'Fault_Log_Parts', 'state', 'order_quantity', 'customer_status_code', 'School_ID', 'section_id', 'Order_items', 'totalenrollment_ay', 'bname', 'date_of_enrolment', 'Violin', \"'Homeland\", 'Certificate', 'job', 'GELL', 'attribute_name', 'savings', 'author_id', 'Injured', 'AND', 'party', 'work_type', 'Role', 'reservations', \"'PU_MAN\", 'staff_department_assignments', 'grade', 'good_or_bad_customer', 'Marketing_Regions', 'date_incident_end', 'Students_in_Detention', 'organisation_Types', 'RANSACTIONS_LOTS', 'County_id', 'LOCATIONS', \"'Email\", 'Good', 'card_id', 'manufacturers', 'camera_lens', 'Number_cities', 'recorded_by_staff_id', 'Apartment_Buildings', 'medicine_id', 'Steven', 'Companies', 'Khanewal', 'Governor', 'Vehicles', 'store_id', 'bandmateid', 'Ref_budget_codes', 'Emma', 'installation_date', 'endowment', 'birth_country', 'catalog_name', 'FJA', 'Rag', \"'Comp\", 'candidate_id', 'shipping_agent_name', 'Host_ID', 'hings', 'INTRODUCTION', 'Sales_in_Billion', 'stu_lname', 'ORG', 'copy_number', 'SHOPS', 'Weber', 'race', 'cinema_id', 'invoice_number', 'coach', 'emp_jobcode', 'Fall', 'individual_last_name', 'How', 'grant_start_date', 'Japan', 'Circulation_History.copy_number', 'PCP', 'Progress', 'Oppose_rate', 'headquartered_city', \"'AIRPORT\", 'Alto', 'Team_id', 'documents', 'Rating', 'billing_state', 'service_id', 'Shanghai', 'arrival_date', 'Age', 'dept_name', 'Meeting', 'Founded', 'Central', 'supplier_phone', 'genre_id', 'college', 'subject_name', 'Feature_ID', 'election', 'warm', 'Student.Fname', 'INVOICES', 'club_id', 'functional_area_description', 'Employee', \"'shopping\", 'catnip', 'Hamburg', 'VICE_President_Vote', 'Planned_Delivery_Date', \"'New\", 'home_game', 'cost', 'Martins', \"'Psychiatry\", 'Democratic', 'Visitors', 'start_date', 'Americano', 'Dec', 'Miramichi', 'register_year', 'channel', \"'Malta\", 'Candidate_ID', 'course_name', 'Title', 'Customer_ID', 'mgr_start_date', 'Scientist', 'intern', 'suppliers', 'sales_billion', 'book_club_id', 'PostalCode', 'embraer.com.br', 'Binders', 'count', 'document_description', 'stageposition', 'Fate', 'product_stock_number', 'CLub', 'BETWEEN', 'Document_date', 'stanley.monahan', \"'Rock\", 'Dameon', 'rental', 'Cobham', \"'Movies\", 'Security', \"'ExxonMobil\", 'Spring', 'Church', 'EMP_NUM', 'browser_id', 'DepartmentID', 'Edmonton', 'shop_id', 'claims', 'onscholarship', 'ResName', 'employees', 'Snatch', 'no_of_loans', 'start_station_id', 'day_Number', 'keyboard', \"'Zach\", 'WiFi', 'Punk', 'station', 'races', 'bikes_available', 'player_name', 'Store_Name', 'Royal_Family_Details', 'Area', \"'doctor\", 'Morning', 'ranking', 'unsure_rate', 'individuals', 'transaction_type_description', 'How_to_Get_There', 'Player_name', 'document_status_description', 'forms', 'captain', 'typical_buying_price', 'Gross_in_dollar', 'payment', 'member_of_club', 'Universal', \"'Art\", 'organisation_details', 'invoice_details', 'Domingo', 'France', 'ALA', 'purchases', 'train_id', 'primary_conference', 'tourist_attraction_id', 'asset_model', 'Catalog_Structure', 'LANGUAGE', 'Department', 'Nancy', \"'Broadband\", 'Eric', 'characteristic_name', 'Geovannyton', \"'DVD\", 'and', 'MARROTTE', 'rental_rate', 'climber', 'gas_station', 'nationality', 'payment_method', 'prereq', 'phone_number', 'STOP', 'client', 'SELECT', 'Advisor', 'built_year', 'Cancel', 'Research_Staff', 'enrollments', 'season', 'Linda', 'products_booked', 'thing_id', 'staff_first_name', 'clubname', 'vocals', 'invested', 'game', 'dormid', 'Years_Played', 'focal_length_mm', 'avg', 'altitude', 'head', \"'yes\", 'song', 'Biale', 'years_working', 'constructorstandings', 'Year_working', 'Points', 'Capital', 'fault_short_name', 'property_id', \"'Loss\", 'Engineer_Visits', 'Document_Types', 'Flash', 'Eliminated_By', 'Prescribes', 'membership_register_branch', 'attribute_value', 'clubdesc', 'United', 'Visits', 'Course_Authors_and_Tutors', 'member_in_charge_id', 'ony', 'Elimination', 'Aircraft_ID', 'f_id', 'card_number', 'address_type_code', 'ransit_Passengers', 'ADDRESSES', 'Marketing_Region_Descriptrion', \"'Goroka\", 'Asset_Parts', 'Songs', 'acc_type', 'Allergy', 'Zieme', 'alent', \"'Midshipman\", 'date_moved_in', 'browser', 's_id', 'Corporation', 'NOISE', 'Widenius', 'You', 'Marina', 'actor', 'Feb', 'dnumber', 'kids', 'film_actor', 'Rent_Arrears', 'billing_country', 'Guruvayur', 'Ref_locations', 'web_client_accelerator', 'Products', 'date_of_transaction', 'Order_ID', 'technician_id', 'fault_log_entry_id', 'Solveig', 'CheckOut', 'Part_Faults', 'operating_system', \"'HUNGER\", 'acceptance', 'g_name', 'Amal', 'artist', 'round', 'Sponsor_name', \"'Success\", 'document_structure_description', 'total_attendance', 'Wiley', 'skill_id', 'num_of_shops', 'hosting_city', 'price_in_dollars', 'amount_outstanding', 'publisher', \"'Triton\", 'hesisin', 'meter_0', 'Products_for_hire', 'organisation_type_description', 'Organizations', 'Midfielder', \"'May\", 'Phantom', \"'saving\", 'Addresses.address_details', 'Artist_ID', 'date', 'roomtype', 'AIB', 'School_Colors', 'Grapes', 'qualification', 'log_entry_date', 'Delivered', 'Santo', \"'HKG\", 'customer_address_history', 'order_item_status', 'Tourist_Attraction_ID', 'Brittany', 'active_to_date', \"'Third-rate\", 'local_authority', 'supplier_id', 'GenreID', 'Shop_Name', 'institution_id', 'subject_id', 'payment_type_code', 'SongId', 'Suppliers', \"'Android\", \"'Win\", 'driver_id', 'Negative', 'Rodrick', 'First_year', 'claims_documents', 'payments', \"'Schmidt\", 'fault_status', 'date_order_placed', 'lot_id', 'Winning_Aircraft', 'affiliation', \"'GT\", 'Date', \"'Book\", 'device', 'Honolulu', 'player', 'booking_start_date', 'Apartments', 'accelerator_id', 'railway', 'school_code', 'policy_id', 'Mike', 'Upgrade', 'Sales', 'county', 'premise_id', 'Gallery', 'Ananthapuri', 'Documents.document_id', 'line', 'customer_details', 'Device_ID', 'organization_id', 'Mark', 'Stores', 'LENGTH', 'Second', 'Country', 'news_report', 'gas', 'year', 'culture_company', 'files', 'Memory_in_G', 'KAWA', 'Market_ID', 'class_section', 'otal_Points', \"'PG\", 'assigned_to_staff_id', 'document_date', 'name', 'Amount_Claimed', 'Credit', 'Jackson', 'sex', 'Heilo', \"'Greenland\", 'company', 'Hill', 'Person', 'Drama_Workshop_Groups', 'departmentID', 'Bdate', 'DESC', 'CWS', 'gameid', 'Right', 'Sonoma', 'Goodrich', 'Location_ID', 'Artist', 'HOTELS', 'Dorian', 'launch', 'exas', 'staff_last_name', 'Circulation_History.employee_id', 'Dining', 'policy', 'Cathrine', 'level', 'customer_address_id', 'pilot_record', 'albumid', 'Ebba', 'wind_speed_mph', 'branch_id', 'asset_make', 'Customer_Email_Address', 'Ueno', \"'Alyson\", 'candidate', 'poll_source', \"'Kenyatta\", \"'Smithson\", 'Statements', 'nurse', 'Physician', \"'Finance\", 'Metallica', 'eqnology', 'Date_of_ceremony', 'Adults', 'problem', 'ObjectNumber', 'team_id_br', 'resident_id', 'Grade', 'Performance_ID', 'max_speed', \"'Cuba\", 'shipment_tracking_number', 'custid', 'inst', 'milliseconds', 'major', 'guest_id', \"'Yale\", 'MAX', 'Other_Details', 'player_college', \"'inhibitor\", \"'Initial\", 'draft_details', 'Bangladesh', 'rental_date', 'bandmate', 'OMIM', \"'Aliens\", 'racy', 'role_code', 'Mountain', 'Industry', 'band', 'Famous_Title', 'rading', 'claims_processing', 'grant_amount', 'church', 'contact_number', 'prepnurse', 'employer_organisation_id', 'architect_id', 'MADLOCK', 'next_entry_id', 'trucks', 'potential', \"'researcher\", 'capacity_percentage', 'church_id', 'Dummy', 'roomName', \"'striker\", \"'Differential\", 'Documents_Mailed.mailed_to_address_id', 'Furniture_ID', 'ASC', 'Police_officers', 'advisor', 'headquarters', 'program_id', \"'Heffington\", 'protein', 'prescribes', \"'Russia\", 'category', 'Explorer', 'Employees.employee_name', 'brand', \"'Washington\", 'ship', 'lat', 'activity', 'Japanese', 'film', 'Motta', 'phone_market', 'distinct', 'projects', 'County', 'AVG', 'Vincent', 'store_name', 'exhibition', 'Participants_in_Events', 'mailshot_customers', 'Organisations', 'Builder', 'Location_Name', 'Aaron', 'acc_percent', 'CMI_Cross_References', 'followers', 'source_u_id', 'elimination', 'structure', \"'King\", 'long', 'i_id', 'max_temperature_f', 'Census_Ranking', 'active', 'Gaming', 'fault_description', 'purchase', 'project_details', \"'BURNS\", 'max_wind_Speed_mph', 'customer_first_name', 'Ref_Transaction_Types', 'Sprint', 'Mancini', 'catalog_id', 'Address_ID', \"'Electoral\", 'commission_pct', 'Birth_Date', 'booked_count', 'Days', 'technician_ID', 'Region_name', \"'Armed\", \"'Cash\", \"'Meaghan\", \"'Close\", 'Manufacturers', 'temperature', 'market_rate', 'Mar', 'Zhejiang', 'list', 'genres', 'tot_cred', 'has_amenity', 'image_name', 'customer_number', 'candidate_assessments', 'Discount_Coupons', 'school_details', 'tracklists', 'oppose_rate', 'middle_name', 'Schuster', 'Silver', 'St.', 'AssignedTo', 'workshop', 'Angeles', 'Participants', \"'Brittany\", 'department_name', 'Before', 'photo', 'grant_id', \"'Research\", 'vbogisich', 'Response', 'preferred_foot', 'end_date', 'COURSE', 'Railway_ID', 'Bernhard', 'Visits_Restaurant', 'furniture_manufacte', 'Working_Horses', 'Blanche', 'Genre', 'min', 'Lacrosse', 'incident_type_code', 'Policy_Type_Code', 'Rock', 'mailing_date', 'total_amount_purchased', 'Kuhn', \"'CCTV\", 'Restaurant_Type.ResTypeName', 'document_code', 'skill_description', 'Prince', 'InvoiceDate', 'date_of_attendance', 'Crescent', 'farm', 'Documents.document_status_code', 'track', 'Editor_ID', 'Company_name', 'takes', 'Jose', 'Parking_Fines', 'Junior', 'People_ID', 'Latin', 'product_details', 'Award', 'date_test_taken', 'Gold', 'Airlines', 'furniture_id', 'authid', \"'CProxy\", 'Club', 'CID', \"'Yes\", \"'Fasterfox\", 'CHRISSY', 'Wales', 'Ray', 'date_from', 'DEPT_NAME', 'Party_ID', 'stu_dob', 'Clients', 'investor_id', 'OURIST_ATTRACTIONS', 'LEVEL', 'club', 'text_of_notes', 'catalog_publisher', 'West', 'Lounge', 'Jun', 'number_deaths', 'interaction_type', 'Wheels', 'Spitzer', 'fastestlapspeed', 'has_allergy', 'shop', 'superstar', 'customers_policies', 'Pen', 'date_claim_made', 'product_suppliers', 'CheckIn', 'Labour', 'typical_selling_price', 'STAFF', 'founded', 'Keeling', \"'London\", 'Restaurant.ResID', 'Code', 'POSITION', 'Rylan', 'Maintenance_Contracts', \"'Clerical\", 'apt_id', 'Long', \"'QM-1\", 'accounts', 'StagePosition', 'Locations', 'LIMIT', 'star_rating_description', 'Residence', 'crs_credit', \"'photo\", \"'Study\", 'gtype', \"'Argentina\", 'Ref_Shipping_Agents', 'movie', 'Aerosmith', 'Arrival', \"'Lieutenant\", 'Attribute_Definitions', 'temporary_acting', 'Invoices', 'Kohler', 'course_description', 'bike_id', 'Low_Estimate', 'MUSEUMS', 'aid', 'journal_committee', 'Issues', 'VISITS', 'publication', 'bangla', 'IHSAA_Football_Class', 'Launched_Year', 'Matthias', 'Settlements', 'multiplayer', 'male_id', 'market_value', 'journalist', 'claim_status_description', 'code', \"'BAL\", 'partitionid', 'Rank_in_Round', 'Attraction_Type_Description', 'artistid', \"'Paper\", 'rating', 'Hometown', 'discipline_enrollments', 'council_tax_id', 'Bradley', 'district', 'Document_locations', 'International_Passengers', 'VOTING_RECORD', 'participant_id', 'example.com', 'review', 'Destiny', 'Grants', 'special_features', 'Artwork_ID', 'location_name', 'used_kb', \"'FedEx\", 'cust_name', 'Howard', 'city_population', \"'PHL\", 'Road', 'operate_company', 'screen_mode', 'chervil', 'Performers', 'store', 'Giuliano', 'min_salary', \"'Kolob\", 'Occupation', 'IATA', 'performance', \"'Canoeing\", 'COUNT', 'shipments', 'country_id', \"'Public\", 'ourist_ID', 'Diana', 'State_County', 'Book_ID', 'Accreditation_level', \"'Progress\", 'working', 'relationship', 'Malaysia', 'drums', 'complaints', 'Forward', 'prominence', 'customer_name', 'Ranking', 'okyo', 'total_budget_percent_budgeted', 'match_result', 'wins', 'graduate', \"'Carol\", 'user_profiles', 'PROF_NUM', 'vehicle_details', 'first_notification_of_loss', 'Ref_Company_Types', 'address_road', 'music_festival', 'organization_name', 'supplier_name', 'hire_date', 'properties', 'uron', 'EmployeeID', 'roller_coaster', 'route_id', 'dateundergoes', 'characteristic_id', 'max', 'Cases', 'Maintenance_Engineers', 'role_name', 'width', 'Appelation', 'SECTION', 'Days_held', 'Start_year', 'Order_Items', 'manager_name', 'Cup', 'Arizona', 'Participant_Details', 'Pixels', \"'Dan\", 'son', 'ime', 'Birth_Place', \"'Mortgages\", 'Researcher', 'university', 'card', 'red', 'Customer_Event_Notes', 'emp_num', 'lastname', 'fast', \"'new\", 'PRODUCTS', 'Male', 'item', 'Documents_with_expenses', 'date_joined_staff', 'mailshot_campaigns', 'emple', 'pets_allowed_yn', 'competition', 'League', 'University', 'authorder', 'city', 'amount_paid', 'test_result', 'Rosalind', 'Database', 'ROOF', 'Labs', 'Support_rate', 'monthly_rental', 'book_title', 'circuits', 'receipt_date', \"'Treasury\", 'COURSES', 'gradepoint', \"'Matter\", 'Product_price', 'stu_gpa', 'SportName', 'raceId', 'Packing', 'furniture', \"'Chris\", 'Gatwick', 'itle', \"'CACHEbox\", 'Ref_Detention_Type', 'document_type_name', 'invoice_date', 'Acknowledgement', 'Draft_Copies', 'Albums', 'Zip_code', 'Customer_Name', 'Damianfort', 'party_events', 'trip', 'lead', 'number_city_affected', 'dept_store_id', 'party_name', 'datetime_detention_end', 'Guests', 'outcome_description', 'Weight', 'Gname', 'photos', 'SALES', 'enzyme', 'Bank', 'Woodroffe', 'inventory', 'allergy', 'EVENTS', 'other_account_details', 'Working_year_starts', 'Langosh', 'Rob', 'Gruber', 'characteristic_data_type', 'Effective_Date', 'Biology', 'exhibition_record', 'Sandwich', \"'Tyler\", 'Uganda', 'customer_events', 'Year', 'Brand', 'account_name', \"'Sonoma\", 'open_year', 'dose', 'customer_code', 'mean_humidity', 'Peeters', 'Accounts', 'Regional_Population', 'UnitPrice', 'formats', 'complaint_status_code', 'Range', \"'Australia\", \"'Procrastin-X\", 'Debit', 'pixels', 'actID', 'Kertzmann', 'LOCATION', 'purchase_details', 'SWEAZY', 'chip_model', 'system', 'name_last', \"'Aripiprazole\", 'death_year', \"'Latte\", 'votes', 'GDP', 'Los', 'high_estimate', 'Proof', 'SupportRepId', 'start', 'Building', 'participants', 'White', 'Num_of_Component', 'reported_by_staff_id', 'NOT', 'OTHA', 'Cancelled', 'Students', 'Barton', 'uid', 'Susan', 'Ship_ID', 'court', 'WHERE', 'Almeida', 'building_address', 'body_builder', 'DPhone', 'region', \"'Clothes\", 'UPS', 'perpetrator', 'ourist_Details', 'contract_end_date', 'birth_place', 'Helena', 'walk', 'Reign', 'Project_Staff', 'customer_contact_channels', 'surname', 'illman', 'synthase', 'asset_acquired_date', 'AlbumID', 'Project_outcomes', 'attendance', 'supplier_addresses', 'Product', 'pages_per_minute_color', 'job_history', 'company_type_code', 'gross_worldwide', 'seating', 'problem_log', 'mean_temperature_f', 'Fname', 'Glenn', 'problem_description', 'PersonFriend', 'Graphics', 'height_feet', 'Member_ID', \"'PUR\", \"'United\", \"'modern\", 'FacID', 'injury', 'length_meters', 'gmail.com', 'date_problem_reported', 'closure_authorised_by_staff_id', \"'Professor\", 'Total_Points', 'Monaco', 'Customer_Orders', 'Phone_ID', 'SCORE', 'lesson_time', 'Addresses.address_id', 'riumfall', 'Ref_Hotel_Star_Ratings', 'Junction', 'Hardware_colours', 'service', 'staff_details', \"'Bob\", 'asset_disposed_date', 'date_assigned_from', 'pName', 'primaryaffiliation', 'channel_code', 'reports_to', 'minister', 'book', 'playlist_tracks', \"'student\", 'Amersham', 'Order_Quantity', 'Mobile', 'Digital', 'Heaney', 'invoice_id', 'Book', \"'engineer\", 'Finance', 'instrument', 'Product_Price', 'department_stores', 'Customer', 'games', 'Festival_Name', 'dept_locations', 'cmi_cross_references', 'program', 'product_quantity', 'Life', 'sent_date', 'Spices', 'Lockmanfurt', \"'Columbia\", 'management', \"'CIS-0\", 'Phone', 'States', 'Smith', 'problem_log_id', 'APPELLATIONs', 'manager_award', \"'checking\", 'Professor', 'Kiss', 'CTO', 'Flight', 'Profits_in_Billion', \"'Denesik\", 'Edwards', 'Debate_ID', 'Starting_year', 'INTERSECT', 'Belgium', 'SUBJECTS', 'on-hold', 'total_pounds', 'Visit_Details', 'address', 'product', 'home_team', 'organized_by', 'course', 'points', 'Wall', 'Student_Tests_Taken', 'managing', 'Hardware_Model_name', 'Manufacturer', 'imed_Locations_of_Things', 'BLOCK', \"'Spring\", 'Category', 'Season', \"'Morning\", 'ext', 'Allergy_Type', 'Atsushi', 'ONDERSMA', 'languages', 'Chiltern', 'District', 'Columbus', \"'Ethiopia\", 'student_course_registrations', 'STUDENTS', 'laurel', 'Rate', 'Services', 'Class_Senator_Vote', 'Date_Claim_Made', 'station_company', 'replacement_cost', 'GRAPES', 'RACHSEL', 'storm', 'International', 'Reader', 'departure_date', 'Florida', 'min_dew_point_f', 'procedures', 'Switzerland', 'claim_headers', 'ArtistId', 'department', 'pID', 'price_in_dollar', 'Prominence', 'email', 'Student.StuID', 'owner', 'Document_Drafts', 'pilot', 'facID', 'organization_contact_individuals', 'HAVING', 'Restaurant_Type.ResTypeID', 'ourist_Attraction_Features', 'Division', 'active_from_date', 'Membership_card', 'Machine_series', 'Resource', 'event_details', 'CRS_CODE', 'ennis', 'Rating_in_percent', \"'McEwen\", 'Time', 'card_type_code', 'yellow', 'stock', 'Aircraft', 'CHI', 'Shop_ID', 'Cameron', 'Pop', \"'Harford\", 'Fahey', 'Economic', 'Blume', 'journal', 'Account_details', 'accelerator_compatible_browser', 'CMI_cross_references', 'jobs', 'Garden', 'settlement_amount', 'cell_mobile_number', 'AKW', 'MTW', 'inventory_id', 'Publisher', \"'Graztevski\", 'age', 'Germany', 'player_id', 'team_id_loser', 'enzyme_id', \"'yellow\", 'null', 'hotel_id', 'activity_name', \"'China\", 'Instructor', 'Ludie', 'Amsterdam', 'modern', 'Store', 'Circulation_History.document_id', 'actual_orders', 'Brazil', 'event_id', \"'Donceel\", 'employee_name', 'purchase_transaction_id', 'teaches', 'Knolls', 'ENROLLED_IN', 'voluptatem', 'feature_Details', 'Dayana', 'AC/DC', 'Ohori', 'driver', \"'Creative\", 'lot_details', 'Boeing', 'editor_id', 'address_details', 'other_characteristic_details', 'shipping_agent_code', \"'Private\", 'employeeid', 'man', 'Representative_Name', 'stop', 'Char_cells', 'Visits_Restaurant.ResID', 'stadium_id', 'PUR', 'flno', 'gold', \"'Heme\", 'directed_by', 'Performance', 'Sons', '...', \"'LINDA\", \"'Accounting\", \"'Sigma\", 'participates_in', 'artist_id', 'attribute_id', 'DEPARTMENT', \"'Marketing\", 'channel_id', 'Indiana', 'All_documents', 'Jeramie', 'Pilot_name', 'registration_id', 'RAM_MiB', 'Palo', 'constructorid', 'Roberto', 'Maudie', 'Georgia', 'max_page_size', 'elevation', 'Gorgoroth', 'journalist_ID', 'database', 'pPos', 'Schultz', 'end_station_name', 'building_id', \"'Steven\", 'Julio', 'Customer_Events', 'Budget_Type_code', 'invoice_lines', 'stadium', 'classroom', 'discount_coupons', 'capacity', 'Draft_Class', 'Rachel', 'Janessa', 'park_name', 'length_feet', 'winning_pilot', 'EXCEPT', 'product_color', 'Becker', 'Catholic', 'date_opened', 'train', 'Service_Type_Code', 'truck_licence_number', \"'Ph.D\", 'done', 'Steve', \"'Clemson\", \"'Fail\", 'LEIA', 'position', \"'Brown\", \"'leader\", 'EVELINA', 'wifi', 'Customers', 'member_name', 'Num_of_shops', 'Prague', 'customer_email', 'unavailable', 'premise_details', \"'Friendly\", 'form_id', 'UID', 'Ref_Attraction_Types', 'Artwork', 'Gender', 'Participates_in', 'playlist_id', 'wrestler', 'View', 'order_shipping_charges', 'English', 'Rohan', 'Election_Cycle', 'dst_apid', 'Defender', 'donator_name', 'supplier_company_id', 'Region', 'score', 'LIKE', 'Australia', 'Jan', 'USPS', 'dept_code', 'loan_type', \"'Surgery\", 'origin', 'amount_piad', 'organisation_type', 'Research_outcomes', 'swimmer', 'GRAPE', 'Eggs', 'Express', 'file_size', 'appointmentid', 'customer_address', 'transaction_type_code', 'Fail', 'Music', \"'KLR9\", 'Country_name', 'customer_last_name', 'Martinez', 'Color', 'player_award', 'Assets_billion', 'MATCH', 'VISITORS', 'Parallax', 'decor', 'protein_name', 'Tourist_ID', 'hot', 'assessment_date', 'EmployeeId', 'Graphics_mode', 'songid', 'Circulation_History', 'maintenance_contract_id', 'Pilot_ID', 'Donor', 'San', 'Kennedy', 'Studio', 'max_gust_speed_mph', 'assignedto', 'CUSTOMERS', 'Alaska', 'ACC_Regular_Season', 'Female', \"'omnis\", 'chromosome', 'password', 'imed_Status_of_Things', 'Ref_colors', \"'Glenn\", 'response_received_date', 'detention_type_code', 'height', 'stu_phone', 'weekly_weather', 'district_name', 'pilot_id', 'invoices', 'Night', 'staystart', 'alid', \"'Aberdare\", 'dorm_name', \"'Cancelled\", 'job_title_code', 'job_title', 'Heathrow', 'detention_summary', 'customer_master_index', 'bedType', 'Killed', 'BirthDate', 'date_of_publication', 'South', 'yCard', 'COVIN', 'the', 'Republican', 'user_login', 'emp_hiredate', 'Brander', 'marketing', 'StuID', 'Participant_Type_Code', 'Latte', 'film_market_estimation', 'RAY', 'Indonesia', 'porphyria', 'medicine', 'on_call', 'Daniel', 'language_id', 'coupon_amount', \"'male\", 'party_email', 'MONTH', 'otal', 'products_for_hire', 'artist_name', \"'sint\", 'apt_number', \"'Physics\", 'Confirmed', 'Count', 'Astrid', 'Date_Claim_Settled', 'Festival_ID', 'amount_payment', 'Walter', 'Marry', 'Northridge', 'enrollment', 'form_name', 'Manager', 'enrico', 'Amount_Payment', 'postseason', 'white', 'min_temperature_f', 'President', 'date_of_notes', 'catalog_contents', 'Headquarter', 'ref_colors', \"'SF\", 'Anthony', 'Representative_ID', 'dependent', 'Office_locations', \"'Albania\", 'Chair_Name', 'ref_product_categories', 'manager_id', 'date_to', 'Wrestler_ID', 'Engineer_Skills', 'store_district', 'basePrice', \"'Full\", 'authors', 'employee_address_id', 'staff_id', 'EACHERS', 'Staff_Roles', 'Num_of_stock', \"'Houston\", 'Coast', 'num_employees', 'Open_Date', 'Votes', 'People', 'mountain_id', \"'Anonymous\", 'BAL', 'customer_phone', 'town_city', 'Project', 'author_or_editor', 'asessment_outcome_code', 'Winning_Pilot', 'Daugavpils', 'LOTS', 'customer_event_id', 'truck_details', 'bookings', 'opening_year', 'Lastname', 'Secretary_Vote', 'record', 'Handful', 'representative', 'route_name', 'created_date', 'year_opened', \"'BUS\", 'Client_ID', 'addresses', 'employee_id', 'Quantity', 'Works', 'institution', 'Football', 'date_of_birth', 'Destroyed_by_Employee_ID', 'ELECTION_CYCLE', 'registration_date', \"'Spouse\", 'Shop_Details', 'total_passengers', 'eachers', 'AFTER', 'schedule', 'room', 'Painless', 'Dublin', 'Decoration_Theme', 'ourist_Attractions', \"'Internet\", 'Submission_ID', 'account_id', 'createdate', 'Nanjing', 'debate', 'Close', 'rem', 'Student.Lname', \"'Denmark\", 'grants', 'Wen', 'lives_in', 'address_id', 'Harris', 'ResTypeDescription', 'STUDENT', 'City_Population', 'East', 'customer', 'date_left_staff', 'Gibbons', \"'Business\", 'Apartment_Facilities', 'Currency_Code', \"'Avatar\", 'billing_city', 'Swift', 'catalog_structure', 'Sportsinfo', 'County_name', 'price', 'regular_order_products', 'Delivery_Routes', 'workshop_id', 'HKG', 'architect', 'Claims', 'Case_burden', 'Card', 'Christop', 'female_id', 'Customer_Payments', 'injury_accident', 'product_price', 'Bell', 'Hours', 'Lacey', 'releasedate', \"'Olympus\", 'Michael', 'Berge', 'credits', 'firstname', 'Hispanic', 'Benefits_Overpayments', 'Attraction_Type_Code', 'SUM', 'Provisional', 'payment_date', 'file', 'Last_year', 'Orton', 'customer_addresses', 'Council_Tax', 'number_of_platforms', 'home_games', 'Milk', 'budget', 'parent_organization_id', 'damage_millions_USD', 'Park', 'CHARACTERISTICS', 'trained_in', \"'Gottlieb\", 'Duplex', 'mean_sea_level_pressure_inches', 'friend', 'Airbus', 'Software_Platform', 'Call', 'CLASS', 'claim_status_name', \"'Billund\", 'Goodwin', 'operating', 'goalie', 'Prix', 'Kaitlyn', 'hometown', 'school', 'RESULT', 'Appropriations', 'school_id', 'company_name', 'network_name', 'Dname', 'Lessons', 'Product_Name', 'CONNECTION', 'member_attendance', 'Birtle', 'campuses', 'JEROME', 'mp4', 'mill', 'is_male', 'view_product_availability', 'DName', 'enroll', 'openning_year', 'master_customer_id', \"'HBS\", 'MediaTypeId', 'Assessment_Notes', \"'American\", 'Model', 'sales', 'AllergyType', 'Financial_transactions', 'Movie', 'instruments', 'Investor_details', 'Clerical', 'movie_id', 'GRADECONVERSION', 'Cows', 'SSN', 'Nationality', 'courses', 'sales_transaction_id', 'Eliot', 'College_ID', 'Competition', 'Ward', 'pitstops', \"'no\", 'dates_active', 'Spanish', 'main_industry', 'Reservations', 'Firstname', 'LORIA', 'Subjects', 'shared', \"'Sarah\", 'Publication_Date', \"'Taiwan\", 'student_capacity', \"'film\", 'max_aperture', 'degrees', 'heme', 'animal', 'actual_order_id', 'Scenes', 'birth_date', \"'female\", 'dept_store_chain_name', 'Sales_billion', 'premises_type', 'date_of_completion', 'club_name', 'rating_in_percent', 'APPELLATIONS', 'order_items', 'JOIN', 'YPE', 'home_city', 'VICE_President_VOTE', 'transaction_type', 'cell_mobile_phone_number', \"'Music\", 'value_points', 'storm_id', \"'Guruvayur\", 'problem_id', 'Editor', 'Samuel', 'organisation_id', 'credit_score', 'ransactions_Lots', 'GenreId', 'HOST', 'cloud_cover', 'RACK', 'Carole', 'Best', 'Weirich', 'School_name', 'hours', 'customers', 'swimmer_id', 'asset_id', 'instid', 'Elaine', 'Annaual', 'World', 'Country_ID', 'Rain', 'label', 'launch_year', 'View_Unit_Status', 'Benjamin', \"'Utah\", 'date_account_opened', 'Lname', 'ARTIST', 'machine', 'Stephanie', \"'Americano\", \"'Math\", 'Student_Course_Enrolment', 'playlists', 'city_id', 'Market_Value_billion', 'amenid', 'Failure', 'budget_type_Description', 'mountain', 'other_details', 'repair_assignment', 'data', 'project', 'blockfloor', 'Elnaugh', \"'Reggae\", 'College', 'region_id', 'entrepreneur', 'class', 'market_share', 'rID', \"'PROF\", 'Nokia', 'Ref_Budget_Codes', 'Employees', 'ResTypeName', 'circuitid', 'postal_code', 'City_Town', 'line_1', 'Residents', 'Museum_Details', \"'Credit\", 'medication', 'Fanny', 'statement_details', 'Detention', 'Restaurant_Type', 'Scanner', 'sesame', 'Number_of_hosts', 'hours_played', 'VIOLENCE', 'Nameless', 'Author', 'day_of_week', 'vehicle_flight_number', 'NYC', 'Recluse', 'MasterCard', \"'Completed\", 'edu', 'film_category', 'host_city', 'London', 'SCIENCE', 'cName', 'Exp', 'Ernser', 'stu_hrs', 'Student_Addresses', 'school_name', 'Customers_cards', 'ties', 'Fault_Log', 'Hopkins', 'game_id', 'Instruments', 'characteristic_type_code', 'Open', 'Nationals', 'James', 'image_url', 'product_id', 'Consider_rate', 'total_value_purchased', 'order_details', 'Enrollment', 'dlocation', 'otal_Horses', 'team_id', 'gname', 'Massively', 'Customer_Event_ID', 'employee_ID', 'Nickname', 'Alison', 'department_id', 'Frami', 'Filming', 'Jeremy', 'Jolie', 'transactions_lots', 'editor', \"'Statistics\", 'ratingDate', 'organization_details', 'Floor_Exercise_Points', 'BROMLEY', 'gender_code', 'airports', 'Fleet_Series', \"'Part\", 'senior', 'Published', 'description', 'target_u_id', 'baseprice', 'rent_arrears', 'paperid', 'Robert', 'Sci', 'authorship', 'scientist', 'Murray', 'date_of_latest_logon', 'High_Estimate', 'shipping_method_code', \"'DRE\", 'MINOR_IN', 'song_name', 'district_id', 'Lifespan', \"'Michael\", 'schooner', 'station_id', 'Destruction_Authorised_by_Employee_ID', 'Bernie', 'last_name', 'fname', 'Badlands', \"'Tax\", 'contract_start_date', 'Francisco', 'Label', 'Human', \"'Psychology\", 'creation', 'chargeable_amount', 'USA', 'Catalog_Contents', 'technician', 'HHH', 'Gym', 'images', 'clublocation', 'emp_fname', 'Application', 'North', 'coach_name', 'Delegate', 'building', 'Clara', 'course_id', \"'ALA\", 'Goldner', 'Patient', 'Robel', 'document_sections', \"'Hardware\", 'order_status', \"'World\", 'Johnson', 'departmentid', 'balance', 'Date_of_Birth', 'Position', 'Documents_with_Expenses', 'Lieutenant_Governor', \"'APRIL\", 'Attendance', 'Skills_Required_To_Fix', 'luisg', 'roomid', 'Other_Item_Details', 'UNION', 'submission', 'service_type_code', 'Programming', 'street_address', 'electoral_register_id', 'Huels', 'Black', \"'MA\", \"'Lasta\", 'Ref_document_types', 'Behavior_Incident', 'Visits_Restaurant.StuID', 'prof_high_degree', 'results', 'email_address', \"'Beijing\", 'stuid', 'york', 'membership_card', 'album_id', 'bedtype', 'Ottilie', 'Uniform', 'slow', 'gamesplayed', 'Price', 'festival_detail', 'Geometry', 'headquarter', 'Seeds', 'store_product', 'document_name', 'stars', \"'Organizer\", 'Soy', 'principal_activities', 'IME', 'products', 'member_id', 'distance', 'market_id', 'away_team', \"'Iceland\", 'Has_allergy', \"'morningside\", 'staff_address_id', 'Shivers', 'President_VOTE', 'Annual_interchanges', 'PURCHASES', \"'Cargo\", 'Activity', 'countries', 'catalog_level_number', 'Kingdom', 'zip_code', 'type_of_Thing_Code', 'LG-P0', 'Sawayn', 'Bob', 'decision', 'Pending', 'Payments', \"'Sponsor\", 'Orders', 'example.org', 'Player', 'budget_in_billions', 'facility_code', 'Ref_Document_Status.document_status_code', 'Completed', 'party_services', 'customer_type_code', 'Gleasonmouth', 'support_rep_id', \"'California\", \"'Iron\", 'Party_name', 'park', 'participant_details', 'Restaurant.ResName', 'lname', \"'Graph\", 'AssistingNurse', 'FDA_approved', 'available_policies', 'Kentucky', 'Video_games', 'STATEMENT_ID', 'Kapitan', \"'Visa\", 'Products_in_Events', 'departments', 'Plays_games', 'FROM', 'document_status_code', 'undergraduate', 'Film', 'FirstName', \"'Cytosol\", 'Systems', 'exhibition_id', 'mascot', 'Store_Email_Address', 'Status', 'maxOccupancy', 'users', 'Lots', 'title', \"'Foot\", \"'History\", 'amount_claimed', 'Statistics', 'Kyle', \"'Fall\", \"'Smith\", 'daily_hire_cost', 'people_addresses', 'Show', 'Team', 'Committee', 'candidates', 'Vote_Percent', 'Product_ID', 'train_station', 'Elimination_Move', \"'Italy\", 'access_count', 'RoomId', 'quantity', 'ype_Of_Restaurant.ResTypeID', 'Writer', 'Player_Attributes', 'county_id', 'total_budget_percent_invested', 'Product_Suppliers', 'START', 'flag', \"'Thompson\", \"'Mary\", 'task_details', 'orders', 'budget_type_description', 'dept_store_chain_id', \"'Gone\", 'director', 'cinema', 'Opera', 'individual_first_name', 'pilot_ID', 'Customer_Policies', 'German', 'Jazz', 'StayID', 'type', 'SALE', 'Eduardo', 'Flat', 'Ref_Incident_Type', 'drive', \"'IT\", 'Budgeted', \"'good\", 'Location_Code', 'consider_rate', 'floors', 'csu_fees', \"'Banking\", 'tryout', 'contact_staff_id', 'Ref_Document_Status.document_status_description', 'Tourist_Details', 'city_area', 'DISTINCT', \"'Canada\", 'aizhou', 'Location', \"'Armani\", 'PIT', 'dname', 'club_rank', 'ROM_MiB', \"'Biology\", 'actid', 'Reviewer', 'ORDER_ITEMS', 'Market_Rate', 'Payment_Method_Code', \"'Knee\", 'left_office', \"'Morocco\", 'Desk', 'laptimes', 'INVESTORS', 'course_Id', 'county_public_safety', 'revenue', 'lesson_id', 'Date_Stored', 'budgeted', 'role_description', 'phone', 'manufacturer_id', 'people', \"'Boston\", 'claim_id', 'Famous_Release_date', 'cmi_cross_ref_id', 'Documents_to_be_destroyed', 'advanced', 'airport_aircraft', 'customer_id', 'apt_type_code', 'Leonie', 'unit_of_measure', 'stay', 'hird_Party_Companies', 'enr', 'Computer', 'Financial_Transactions', 'address_line_1', \"'Sony\", 'Zinfandel', 'Documents', 'Player_id', 'FIFA', 'Documents.shipping_agent_code', \"'Afghanistan\", 'region_code', 'bedroom_count', 'Young', 'trade_name', 'Musical_ID', 'Collectible', 'Jaskolski', 'gender', 'film_id', 'average_attendance', 'teachers', 'building_full_name', 'ALBUM', 'County_ID', 'Soisalon', 'Matters', 'Num_of_Audience', 'SOURCE', 'Der', 'Duke', 'Insurance', 'amount_of_refund', 'Store_Phone', 'Address', 'SECRETARY_Vote', 'lesson_status_code', 'region_name', 'Subway', 'buildings', 'Venue', 'Market_Value_in_Billion', 'Brandon', 'follows', 'Visits_Restaurant.Spent', 'document_sections_images', 'Ref_Shipping_Agents.shipping_agent_name', 'Payment_ID', 'Party', \"'Grondzeiler\", 'student_id', 'took_office', \"'Hartford\", 'Derricks', \"'Barker\", 'premises', 'Courses', 'jeans', 'date_of_latest_revision', 'eid', 'part_name', 'CName', 'apid', 'Email', 'individual_middle_name', 'Kim', 'Denomination', 'Profits_billion', 'prereq_id', 'Lyla', 'founder', 'complaint_type_code', 'mp3', 'Skills', 'COMPUTER', 'order_date', \"'NY\", \"'Andy\", 'Weeks_on_Top', 'Treasurer_Vote', 'part_fault_id', \"'Payam\", 'Director', 'crossing', 'coupon_id', 'date_stored', 'claim_stage_id', 'task_id', 'Queen', 'Jul', 'genre', 'Wyman', 'Awarded', 'datetime_detention_start', 'physician', 'Documents_Mailed', 'Marcelle', \"'Photo\", 'PRESIDENT_Vote', 'party_forms', 'Document_name', 'ticket_price', 'checking', 'Roles.role_code', 'Dependent_name', 'participant_type_code', \"'english\", 'number_of_matches', 'debate_people', 'broadcast', 'high_temperature', 'Population', 'CustomerId', 'u_id', 'personal_name', 'CLASS_President_VOTE', 'useracct', 'Policy', 'Lake', 'Event_Name', 'people_id', 'wedding', 'Peter', 'Bootup', 'Time_of_day', 'Fordham', 'LName', 'David', 'cmi_details', 'catalog_entry_name', 'campusfee', 'GENRE', 'country', 'media_type_id', 'Cat', 'Stockings', 'Share_in_percent', 'Mergenthaler', 'Street_Markets', \"'Oil\", 'manufacturer', 'Accreditation_type', 'team_franchise', 'Robinson', 'Claim_id', 'DAMIEN', 'Has_Allergy', 'Horizontal_Bar_Points', 'happy_hour', 'Company', 'ROY', \"'FL\", 'POLLOCK', 'Arch', 'line_number_building', \"'activitor\", 'AMI', 'Ref_Document_Status', 'Band', 'Price_in_Dollar', 'precipitation', 'asset_details', 'Wisconsin', 'audio', 'catalog_entry_id', 'Player_ID', 'beds', 'Shark', \"'Provisional\", 'velocity', \"'Lamberton\", 'Staff_Department_Assignments', 'emp_dob', 'Chicago', 'bus', 'no_of_customers', 'MPEG', \"'USA\", 'China', \"'Walter\", 'right', \"'Unsatisfied\", 'staff_name', 'team', 'January', 'student', 'Employees.employee_id', \"'Austin\", 'group_equity_shareholding', 'Miss', 'ime_of_purchase', 'Police_force', \"'ACCT-1\", 'Canada', 'settlements', \"'Black\", \"'Charles\", 'date_complaint_raised', 'aut', 'Service_Type_Description', \"'quo\", 'Mascot', 'INVOICE', 'budget_type_code', 'Launch_year', 'Lisa', 'basketball_match', 'York', 'Kitty', 'first_name', 'services', 'Olin', 'Atlas', 'festival', 'Ref_calendar', 'weight', 'MIN', 'date_contact_to', 'building_manager', 'Result', 'Alex', 'AsstProf', 'Aniyah', 'catalogs', 'claim_header_id', 'Coach_ID', 'guest_first_name', \"'Atlanta\", \"'GV\", 'date_formed', 'drivers', 'student_details', 'product_characteristics', 'Shea', 'Lee', 'nickname', 'Comptroller', 'product_category', 'ASSESSMENT_NOTES', \"'Amisulpride\", \"'Mobile\", \"'Canadian\", 'People_id', 'family_name', 'Business_Rates', 'location', 'Feest', 'Duration', 'state_province_county', 'rid', 'star_rating_code', \"'goalie\", 'Ref_Shipping_Agents.shipping_agent_code', 'location_id', \"'Auto\", 'product_category_code', 'Addresses', 'Simon', 'Julianaside', 'driverId', 'Representative', 'Man', 'BillingCountry', \"'Opera\", 'bats', 'Medication', 'Status_of_Thing_Code', 'flight', 'dar', 'Starting_Year', 'SELBIG', 'Demon', 'Years_working', 'scientists', 'Monadic', 'Opening_Hours', 'Leader_Name', 'Spent', 'journal_ID', 'Chico', 'product_name', 'Deleted', 'stu_fname', 'love', \"'bad\", \"'Hiram\", 'date_incident_start', 'num_of_staff', \"'Order\", 'manager', 'amount_due', 'section_title', 'date_closed', 'Colorado', 'all_star', 'sales_details', 'person_id', 'customer_orders', \"'No\", 'routes', 'patient', 'cumin', 'Monterey', 'Total_Passengers', \"'Safari\", 'Harold', 'tweets', 'document_structures', 'Club_ID', 'Open_Year', 'uk_vat_number', 'Projects', 'LITERACY', 'date_assigned_to', 'Affirmative', 'students', 'semester', 'dorm', 'functional_area_code', 'artists', 'Scores', 'login_name', 'Lubowitz', \"'Mark\", 'Song', 'Date_Payment_Made', 'forename', 'Workshop_Group_ID', 'Williams', \"'Tokyo\", \"'park\", 'book_club', 'Retailing', 'Customer_Phone', 'Registration_Date', 'snatch', 'policies', 'raceid', 'Album', 'show_times_per_day', 'document_functional_areas', 'Roles.role_description', 'affected_region', 'mean_visibility_miles', 'Stay', 'form_type_code', 'traditional', 'sum', 'location_code', 'bathroom_count', 'cust_id', 'Milliseconds', 'Blackville', 'Primary_conference', 'Nominated', 'KIRK', 'ARRING', 'total', 'EMPLOYEE', 'time', 'AlbumId', 'defiance', 'Actual_Delivery_Date', 'VICE_PRESIDENT_Vote', 'emp_lname', 'Room', 'employment', 'faculty', 'Allergy_type', 'CLE', 'Katsuhiro', 'Event_Attendance', 'color', 'Product_Type_Code', 'Deputy', 'All_Home', 'ROYAL_FAMILY', 'party_id', 'pop', 'Date_and_Date', 'Order_Date', 'Jerry', 'Champlin', 'route', 'member', 'okohu', 'price_in_euros', 'venue', 'clubid', 'journalist_id', 'Spain', 'Mountain_ID', 'HOU', \"'TV\", 'residence', 'Airport', 'project_id', 'regional_population', 'Operating_system', 'Join_Year', 'CLASS_Senator_VOTE', 'amenity_name'}\n"
     ]
    }
   ],
   "source": [
    "# #to store the vocabulary\n",
    "# vocab = []\n",
    "# rgx_list = [\"^T|t\\d.\",\"\\d.\"]\n",
    "# for name in transform_data[:,0]:\n",
    "#     for i in word_tokenize(name):\n",
    "#         txt = clean_text(rgx_list,i)\n",
    "#         if(len(txt)>2):\n",
    "#             vocab.append(txt)\n",
    "\n",
    "# vocab = set(vocab)\n",
    "# vocab_size = len(vocab)\n",
    "\n",
    "# print(\"Vocab size = {}\".format(len(vocab)))\n",
    "# print(\"Vocab      = {}\".format(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 83\n",
      "Vocab      = {'6', '3', '2', 'Y', 'C', ',', '%', 'k', 'w', '0', 'T', 'N', 'M', 'K', 'q', ' ', 'n', 'I', 'P', 'U', '1', 'G', 'E', 's', '*', 'p', 'Q', 'X', \"'\", '!', '<', 'y', '8', 'O', 'h', 'l', 'W', ':', 'D', 'm', '.', 'S', '/', '@', ';', '\"', 'g', '_', 'A', 'z', ')', 'b', 'e', 't', 'R', 'u', 'j', 'r', '>', 'H', 'f', '-', 'F', '+', '\\t', '(', 'V', 'L', 'o', '9', '=', 'i', '7', 'd', '4', 'a', 'x', 'J', 'v', 'Z', '5', 'B', 'c'}\n"
     ]
    }
   ],
   "source": [
    "#to store the vocabulary\n",
    "vocab = list()\n",
    "for name in transform_data[:,0]:\n",
    "    vocab.extend(list(name))\n",
    "\n",
    "vocab = set(vocab)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(\"Vocab size = {}\".format(len(vocab)))\n",
    "print(\"Vocab      = {}\".format(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s-41, 22-E\n"
     ]
    }
   ],
   "source": [
    "#map char to id and id to chars\n",
    "char_id = dict()\n",
    "id_char = dict()\n",
    "\n",
    "for i,char in enumerate(vocab):\n",
    "    char_id[char] = i\n",
    "    id_char[i] = char\n",
    "\n",
    "print('s-{}, 22-{}'.format(char_id['S'],id_char[22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of batches of size = 20\n",
    "train_dataset = []\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#split the trasnform data into batches of 20\n",
    "for i in range(len(transform_data)-batch_size+1):\n",
    "    start = i*batch_size\n",
    "    end = start+batch_size\n",
    "    \n",
    "    #batch data\n",
    "    batch_data = transform_data[start:end]\n",
    "    \n",
    "    if(len(batch_data)!=batch_size):\n",
    "        break\n",
    "        \n",
    "    #convert each char of each name of batch data into one hot encoding\n",
    "    char_list = []\n",
    "    for k in range(len(batch_data[0][0])):\n",
    "        batch_dataset = np.zeros([batch_size,len(vocab)])\n",
    "        for j in range(batch_size):\n",
    "            name = batch_data[j][0]\n",
    "            char_index = char_id[name[k]]\n",
    "            batch_dataset[j,char_index] = 1.0\n",
    "     \n",
    "        #store the ith char's one hot representation of each name in batch_data\n",
    "        char_list.append(batch_dataset)\n",
    "    \n",
    "    #store each char's of every name in batch dataset into train_dataset\n",
    "    train_dataset.append(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of input units or embedding size\n",
    "input_units = 100\n",
    "\n",
    "#number of hidden neurons\n",
    "hidden_units = 256\n",
    "\n",
    "#number of output units i.e vocab size\n",
    "output_units = vocab_size\n",
    "\n",
    "#learning rate\n",
    "learning_rate = 0.005\n",
    "\n",
    "#beta1 for V parameters used in Adam Optimizer\n",
    "beta1 = 0.90\n",
    "\n",
    "#beta2 for S parameters used in Adam Optimizer\n",
    "beta2 = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Functions\n",
    "#sigmoid\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "#tanh activation\n",
    "def tanh_activation(X):\n",
    "    return np.tanh(X)\n",
    "\n",
    "#softmax activation\n",
    "def softmax(X):\n",
    "    exp_X = np.exp(X)\n",
    "    exp_X_sum = np.sum(exp_X,axis=1).reshape(-1,1)\n",
    "    exp_X = exp_X/exp_X_sum\n",
    "    return exp_X\n",
    "\n",
    "#derivative of tanh\n",
    "def tanh_derivative(X):\n",
    "    return 1-(X**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize parameters\n",
    "def initialize_parameters():\n",
    "    #initialize the parameters with 0 mean and 0.01 standard deviation\n",
    "    mean = 0\n",
    "    std = 0.01\n",
    "    \n",
    "    #lstm cell weights\n",
    "    forget_gate_weights = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    input_gate_weights  = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    output_gate_weights = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    gate_gate_weights   = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    \n",
    "    #hidden to output weights (output cell)\n",
    "    hidden_output_weights = np.random.normal(mean,std,(hidden_units,output_units))\n",
    "    \n",
    "    parameters = dict()\n",
    "    parameters['fgw'] = forget_gate_weights\n",
    "    parameters['igw'] = input_gate_weights\n",
    "    parameters['ogw'] = output_gate_weights\n",
    "    parameters['ggw'] = gate_gate_weights\n",
    "    parameters['how'] = hidden_output_weights\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single lstm cell\n",
    "def lstm_cell(batch_dataset, prev_activation_matrix, prev_cell_matrix, parameters):\n",
    "    #get parameters\n",
    "    fgw = parameters['fgw']\n",
    "    igw = parameters['igw']\n",
    "    ogw = parameters['ogw']\n",
    "    ggw = parameters['ggw']\n",
    "    \n",
    "    #concat batch data and prev_activation matrix\n",
    "    concat_dataset = np.concatenate((batch_dataset,prev_activation_matrix),axis=1)\n",
    "    \n",
    "    #forget gate activations\n",
    "    fa = np.matmul(concat_dataset,fgw)\n",
    "    fa = sigmoid(fa)\n",
    "    \n",
    "    #input gate activations\n",
    "    ia = np.matmul(concat_dataset,igw)\n",
    "    ia = sigmoid(ia)\n",
    "    \n",
    "    #output gate activations\n",
    "    oa = np.matmul(concat_dataset,ogw)\n",
    "    oa = sigmoid(oa)\n",
    "    \n",
    "    #gate gate activations\n",
    "    ga = np.matmul(concat_dataset,ggw)\n",
    "    ga = tanh_activation(ga)\n",
    "    \n",
    "    #new cell memory matrix\n",
    "    cell_memory_matrix = np.multiply(fa,prev_cell_matrix) + np.multiply(ia,ga)\n",
    "    \n",
    "    #current activation matrix\n",
    "    activation_matrix = np.multiply(oa, tanh_activation(cell_memory_matrix))\n",
    "    \n",
    "    #lets store the activations to be used in back prop\n",
    "    lstm_activations = dict()\n",
    "    lstm_activations['fa'] = fa\n",
    "    lstm_activations['ia'] = ia\n",
    "    lstm_activations['oa'] = oa\n",
    "    lstm_activations['ga'] = ga\n",
    "    \n",
    "    return lstm_activations,cell_memory_matrix,activation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_cell(activation_matrix,parameters):\n",
    "    #get hidden to output parameters\n",
    "    how = parameters['how']\n",
    "    \n",
    "    #get outputs \n",
    "    output_matrix = np.matmul(activation_matrix,how)\n",
    "    output_matrix = softmax(output_matrix)\n",
    "    \n",
    "    return output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(batch_dataset,embeddings):\n",
    "    embedding_dataset = np.matmul(batch_dataset,embeddings)\n",
    "    return embedding_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propagation\n",
    "def forward_propagation(batches,parameters,embeddings):\n",
    "    #get batch size\n",
    "    batch_size = batches[0].shape[0]\n",
    "    \n",
    "    #to store the activations of all the unrollings.\n",
    "    lstm_cache = dict()                 #lstm cache\n",
    "    activation_cache = dict()           #activation cache \n",
    "    cell_cache = dict()                 #cell cache\n",
    "    output_cache = dict()               #output cache\n",
    "    embedding_cache = dict()            #embedding cache \n",
    "    \n",
    "    #initial activation_matrix(a0) and cell_matrix(c0)\n",
    "    a0 = np.zeros([batch_size,hidden_units],dtype=np.float32)\n",
    "    c0 = np.zeros([batch_size,hidden_units],dtype=np.float32)\n",
    "    \n",
    "    #store the initial activations in cache\n",
    "    activation_cache['a0'] = a0\n",
    "    cell_cache['c0'] = c0\n",
    "    \n",
    "    #unroll the names\n",
    "    for i in range(len(batches)-1):\n",
    "        #get first first character batch\n",
    "        batch_dataset = batches[i]\n",
    "        \n",
    "        #get embeddings \n",
    "        batch_dataset = get_embeddings(batch_dataset,embeddings)\n",
    "        embedding_cache['emb'+str(i)] = batch_dataset\n",
    "        \n",
    "        #lstm cell\n",
    "        lstm_activations,ct,at = lstm_cell(batch_dataset,a0,c0,parameters)\n",
    "        \n",
    "        #output cell\n",
    "        ot = output_cell(at,parameters)\n",
    "        \n",
    "        #store the time 't' activations in caches\n",
    "        lstm_cache['lstm' + str(i+1)]  = lstm_activations\n",
    "        activation_cache['a'+str(i+1)] = at\n",
    "        cell_cache['c' + str(i+1)] = ct\n",
    "        output_cache['o'+str(i+1)] = ot\n",
    "        \n",
    "        #update a0 and c0 to new 'at' and 'ct' for next lstm cell\n",
    "        a0 = at\n",
    "        c0 = ct\n",
    "        \n",
    "    return embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate loss, perplexity and accuracy\n",
    "def cal_loss_accuracy(batch_labels,output_cache):\n",
    "    loss = 0  #to sum loss for each time step\n",
    "    acc  = 0  #to sum acc for each time step \n",
    "    prob = 1  #probability product of each time step predicted char\n",
    "    \n",
    "    #batch size\n",
    "    batch_size = batch_labels[0].shape[0]\n",
    "    \n",
    "    #loop through each time step\n",
    "    for i in range(1,len(output_cache)+1):\n",
    "        #get true labels and predictions\n",
    "        labels = batch_labels[i]\n",
    "        pred = output_cache['o'+str(i)]\n",
    "        \n",
    "        prob = np.multiply(prob,np.sum(np.multiply(labels,pred),axis=1).reshape(-1,1))\n",
    "        loss += np.sum((np.multiply(labels,np.log(pred)) + np.multiply(1-labels,np.log(1-pred))),axis=1).reshape(-1,1)\n",
    "        acc  += np.array(np.argmax(labels,1)==np.argmax(pred,1),dtype=np.float32).reshape(-1,1)\n",
    "    \n",
    "    #calculate perplexity loss and accuracy\n",
    "    perplexity = np.sum((1/prob)**(1/len(output_cache)))/batch_size\n",
    "    loss = np.sum(loss)*(-1/batch_size)\n",
    "    acc  = np.sum(acc)/(batch_size)\n",
    "    acc = acc/len(output_cache)\n",
    "    \n",
    "    return perplexity,loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate output cell errors\n",
    "def calculate_output_cell_error(batch_labels,output_cache,parameters):\n",
    "    #to store the output errors for each time step\n",
    "    output_error_cache = dict()\n",
    "    activation_error_cache = dict()\n",
    "    how = parameters['how']\n",
    "    \n",
    "    #loop through each time step\n",
    "    for i in range(1,len(output_cache)+1):\n",
    "        #get true and predicted labels\n",
    "        labels = batch_labels[i]\n",
    "        pred = output_cache['o'+str(i)]\n",
    "        \n",
    "        #calculate the output_error for time step 't'\n",
    "        error_output = pred - labels\n",
    "        \n",
    "        #calculate the activation error for time step 't'\n",
    "        error_activation = np.matmul(error_output,how.T)\n",
    "        \n",
    "        #store the output and activation error in dict\n",
    "        output_error_cache['eo'+str(i)] = error_output\n",
    "        activation_error_cache['ea'+str(i)] = error_activation\n",
    "        \n",
    "    return output_error_cache,activation_error_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate error for single lstm cell\n",
    "def calculate_single_lstm_cell_error(activation_output_error,next_activation_error,next_cell_error,parameters,lstm_activation,cell_activation,prev_cell_activation):\n",
    "    #activation error =  error coming from output cell and error coming from the next lstm cell\n",
    "    activation_error = activation_output_error + next_activation_error\n",
    "    \n",
    "    #output gate error\n",
    "    oa = lstm_activation['oa']\n",
    "    eo = np.multiply(activation_error,tanh_activation(cell_activation))\n",
    "    eo = np.multiply(np.multiply(eo,oa),1-oa)\n",
    "    \n",
    "    #cell activation error\n",
    "    cell_error = np.multiply(activation_error,oa)\n",
    "    cell_error = np.multiply(cell_error,tanh_derivative(tanh_activation(cell_activation)))\n",
    "    #error also coming from next lstm cell \n",
    "    cell_error += next_cell_error\n",
    "    \n",
    "    #input gate error\n",
    "    ia = lstm_activation['ia']\n",
    "    ga = lstm_activation['ga']\n",
    "    ei = np.multiply(cell_error,ga)\n",
    "    ei = np.multiply(np.multiply(ei,ia),1-ia)\n",
    "    \n",
    "    #gate gate error\n",
    "    eg = np.multiply(cell_error,ia)\n",
    "    eg = np.multiply(eg,tanh_derivative(ga))\n",
    "    \n",
    "    #forget gate error\n",
    "    fa = lstm_activation['fa']\n",
    "    ef = np.multiply(cell_error,prev_cell_activation)\n",
    "    ef = np.multiply(np.multiply(ef,fa),1-fa)\n",
    "    \n",
    "    #prev cell error\n",
    "    prev_cell_error = np.multiply(cell_error,fa)\n",
    "    \n",
    "    #get parameters\n",
    "    fgw = parameters['fgw']\n",
    "    igw = parameters['igw']\n",
    "    ggw = parameters['ggw']\n",
    "    ogw = parameters['ogw']\n",
    "    \n",
    "    #embedding + hidden activation error\n",
    "    embed_activation_error = np.matmul(ef,fgw.T)\n",
    "    embed_activation_error += np.matmul(ei,igw.T)\n",
    "    embed_activation_error += np.matmul(eo,ogw.T)\n",
    "    embed_activation_error += np.matmul(eg,ggw.T)\n",
    "    \n",
    "    input_hidden_units = fgw.shape[0]\n",
    "    hidden_units = fgw.shape[1]\n",
    "    input_units = input_hidden_units - hidden_units\n",
    "    \n",
    "    #prev activation error\n",
    "    prev_activation_error = embed_activation_error[:,input_units:]\n",
    "    \n",
    "    #input error (embedding error)\n",
    "    embed_error = embed_activation_error[:,:input_units]\n",
    "    \n",
    "    #store lstm error\n",
    "    lstm_error = dict()\n",
    "    lstm_error['ef'] = ef\n",
    "    lstm_error['ei'] = ei\n",
    "    lstm_error['eo'] = eo\n",
    "    lstm_error['eg'] = eg\n",
    "    \n",
    "    return prev_activation_error,prev_cell_error,embed_error,lstm_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate output cell derivatives\n",
    "def calculate_output_cell_derivatives(output_error_cache,activation_cache,parameters):\n",
    "    #to store the sum of derivatives from each time step\n",
    "    dhow = np.zeros(parameters['how'].shape)\n",
    "    \n",
    "    batch_size = activation_cache['a1'].shape[0]\n",
    "    \n",
    "    #loop through the time steps \n",
    "    for i in range(1,len(output_error_cache)+1):\n",
    "        #get output error\n",
    "        output_error = output_error_cache['eo' + str(i)]\n",
    "        \n",
    "        #get input activation\n",
    "        activation = activation_cache['a'+str(i)]\n",
    "        \n",
    "        #cal derivative and summing up!\n",
    "        dhow += np.matmul(activation.T,output_error)/batch_size\n",
    "        \n",
    "    return dhow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate derivatives for single lstm cell\n",
    "def calculate_single_lstm_cell_derivatives(lstm_error,embedding_matrix,activation_matrix):\n",
    "    #get error for single time step\n",
    "    ef = lstm_error['ef']\n",
    "    ei = lstm_error['ei']\n",
    "    eo = lstm_error['eo']\n",
    "    eg = lstm_error['eg']\n",
    "    \n",
    "    #get input activations for this time step\n",
    "    concat_matrix = np.concatenate((embedding_matrix,activation_matrix),axis=1)\n",
    "    \n",
    "    batch_size = embedding_matrix.shape[0]\n",
    "    \n",
    "    #cal derivatives for this time step\n",
    "    dfgw = np.matmul(concat_matrix.T,ef)/batch_size\n",
    "    digw = np.matmul(concat_matrix.T,ei)/batch_size\n",
    "    dogw = np.matmul(concat_matrix.T,eo)/batch_size\n",
    "    dggw = np.matmul(concat_matrix.T,eg)/batch_size\n",
    "    \n",
    "    #store the derivatives for this time step in dict\n",
    "    derivatives = dict()\n",
    "    derivatives['dfgw'] = dfgw\n",
    "    derivatives['digw'] = digw\n",
    "    derivatives['dogw'] = dogw\n",
    "    derivatives['dggw'] = dggw\n",
    "    \n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backpropagation\n",
    "def backward_propagation(batch_labels,embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache,parameters):\n",
    "    #calculate output errors \n",
    "    output_error_cache,activation_error_cache = calculate_output_cell_error(batch_labels,output_cache,parameters)\n",
    "    \n",
    "    #to store lstm error for each time step\n",
    "    lstm_error_cache = dict()\n",
    "    \n",
    "    #to store embeding errors for each time step\n",
    "    embedding_error_cache = dict()\n",
    "    \n",
    "    # next activation error \n",
    "    # next cell error  \n",
    "    #for last cell will be zero\n",
    "    eat = np.zeros(activation_error_cache['ea1'].shape)\n",
    "    ect = np.zeros(activation_error_cache['ea1'].shape)\n",
    "    \n",
    "    #calculate all lstm cell errors (going from last time-step to the first time step)\n",
    "    for i in range(len(lstm_cache),0,-1):\n",
    "        #calculate the lstm errors for this time step 't'\n",
    "        pae,pce,ee,le = calculate_single_lstm_cell_error(activation_error_cache['ea'+str(i)],eat,ect,parameters,lstm_cache['lstm'+str(i)],cell_cache['c'+str(i)],cell_cache['c'+str(i-1)])\n",
    "        \n",
    "        #store the lstm error in dict\n",
    "        lstm_error_cache['elstm'+str(i)] = le\n",
    "        \n",
    "        #store the embedding error in dict\n",
    "        embedding_error_cache['eemb'+str(i-1)] = ee\n",
    "        \n",
    "        #update the next activation error and next cell error for previous cell\n",
    "        eat = pae\n",
    "        ect = pce\n",
    "    \n",
    "    \n",
    "    #calculate output cell derivatives\n",
    "    derivatives = dict()\n",
    "    derivatives['dhow'] = calculate_output_cell_derivatives(output_error_cache,activation_cache,parameters)\n",
    "    \n",
    "    #calculate lstm cell derivatives for each time step and store in lstm_derivatives dict\n",
    "    lstm_derivatives = dict()\n",
    "    for i in range(1,len(lstm_error_cache)+1):\n",
    "        lstm_derivatives['dlstm'+str(i)] = calculate_single_lstm_cell_derivatives(lstm_error_cache['elstm'+str(i)],embedding_cache['emb'+str(i-1)],activation_cache['a'+str(i-1)])\n",
    "    \n",
    "    #initialize the derivatives to zeros \n",
    "    derivatives['dfgw'] = np.zeros(parameters['fgw'].shape)\n",
    "    derivatives['digw'] = np.zeros(parameters['igw'].shape)\n",
    "    derivatives['dogw'] = np.zeros(parameters['ogw'].shape)\n",
    "    derivatives['dggw'] = np.zeros(parameters['ggw'].shape)\n",
    "    \n",
    "    #sum up the derivatives for each time step\n",
    "    for i in range(1,len(lstm_error_cache)+1):\n",
    "        derivatives['dfgw'] += lstm_derivatives['dlstm'+str(i)]['dfgw']\n",
    "        derivatives['digw'] += lstm_derivatives['dlstm'+str(i)]['digw']\n",
    "        derivatives['dogw'] += lstm_derivatives['dlstm'+str(i)]['dogw']\n",
    "        derivatives['dggw'] += lstm_derivatives['dlstm'+str(i)]['dggw']\n",
    "    \n",
    "    return derivatives,embedding_error_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the parameters using adam optimizer\n",
    "#adam optimization\n",
    "def update_parameters(parameters,derivatives,V,S,t):\n",
    "    #get derivatives\n",
    "    dfgw = derivatives['dfgw']\n",
    "    digw = derivatives['digw']\n",
    "    dogw = derivatives['dogw']\n",
    "    dggw = derivatives['dggw']\n",
    "    dhow = derivatives['dhow']\n",
    "    \n",
    "    #get parameters\n",
    "    fgw = parameters['fgw']\n",
    "    igw = parameters['igw']\n",
    "    ogw = parameters['ogw']\n",
    "    ggw = parameters['ggw']\n",
    "    how = parameters['how']\n",
    "    \n",
    "    #get V parameters\n",
    "    vfgw = V['vfgw']\n",
    "    vigw = V['vigw']\n",
    "    vogw = V['vogw']\n",
    "    vggw = V['vggw']\n",
    "    vhow = V['vhow']\n",
    "    \n",
    "    #get S parameters\n",
    "    sfgw = S['sfgw']\n",
    "    sigw = S['sigw']\n",
    "    sogw = S['sogw']\n",
    "    sggw = S['sggw']\n",
    "    show = S['show']\n",
    "    \n",
    "    #calculate the V parameters from V and current derivatives\n",
    "    vfgw = (beta1*vfgw + (1-beta1)*dfgw)\n",
    "    vigw = (beta1*vigw + (1-beta1)*digw)\n",
    "    vogw = (beta1*vogw + (1-beta1)*dogw)\n",
    "    vggw = (beta1*vggw + (1-beta1)*dggw)\n",
    "    vhow = (beta1*vhow + (1-beta1)*dhow)\n",
    "    \n",
    "    #calculate the S parameters from S and current derivatives\n",
    "    sfgw = (beta2*sfgw + (1-beta2)*(dfgw**2))\n",
    "    sigw = (beta2*sigw + (1-beta2)*(digw**2))\n",
    "    sogw = (beta2*sogw + (1-beta2)*(dogw**2))\n",
    "    sggw = (beta2*sggw + (1-beta2)*(dggw**2))\n",
    "    show = (beta2*show + (1-beta2)*(dhow**2))\n",
    "    \n",
    "    #update the parameters\n",
    "    fgw = fgw - learning_rate*((vfgw)/(np.sqrt(sfgw) + 1e-6))\n",
    "    igw = igw - learning_rate*((vigw)/(np.sqrt(sigw) + 1e-6))\n",
    "    ogw = ogw - learning_rate*((vogw)/(np.sqrt(sogw) + 1e-6))\n",
    "    ggw = ggw - learning_rate*((vggw)/(np.sqrt(sggw) + 1e-6))\n",
    "    how = how - learning_rate*((vhow)/(np.sqrt(show) + 1e-6))\n",
    "    \n",
    "    #store the new weights\n",
    "    parameters['fgw'] = fgw\n",
    "    parameters['igw'] = igw\n",
    "    parameters['ogw'] = ogw\n",
    "    parameters['ggw'] = ggw\n",
    "    parameters['how'] = how\n",
    "    \n",
    "    #store the new V parameters\n",
    "    V['vfgw'] = vfgw \n",
    "    V['vigw'] = vigw \n",
    "    V['vogw'] = vogw \n",
    "    V['vggw'] = vggw\n",
    "    V['vhow'] = vhow\n",
    "    \n",
    "    #store the s parameters\n",
    "    S['sfgw'] = sfgw \n",
    "    S['sigw'] = sigw \n",
    "    S['sogw'] = sogw \n",
    "    S['sggw'] = sggw\n",
    "    S['show'] = show\n",
    "    \n",
    "    return parameters,V,S    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the Embeddings\n",
    "def update_embeddings(embeddings,embedding_error_cache,batch_labels):\n",
    "    #to store the embeddings derivatives\n",
    "    embedding_derivatives = np.zeros(embeddings.shape)\n",
    "    \n",
    "    batch_size = batch_labels[0].shape[0]\n",
    "    \n",
    "    #sum the embedding derivatives for each time step\n",
    "    for i in range(len(embedding_error_cache)):\n",
    "        embedding_derivatives += np.matmul(batch_labels[i].T,embedding_error_cache['eemb'+str(i)])/batch_size\n",
    "    \n",
    "    #update the embeddings\n",
    "    embeddings = embeddings - learning_rate*embedding_derivatives\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_V(parameters):\n",
    "    Vfgw = np.zeros(parameters['fgw'].shape)\n",
    "    Vigw = np.zeros(parameters['igw'].shape)\n",
    "    Vogw = np.zeros(parameters['ogw'].shape)\n",
    "    Vggw = np.zeros(parameters['ggw'].shape)\n",
    "    Vhow = np.zeros(parameters['how'].shape)\n",
    "    \n",
    "    V = dict()\n",
    "    V['vfgw'] = Vfgw\n",
    "    V['vigw'] = Vigw\n",
    "    V['vogw'] = Vogw\n",
    "    V['vggw'] = Vggw\n",
    "    V['vhow'] = Vhow\n",
    "    return V\n",
    "\n",
    "def initialize_S(parameters):\n",
    "    Sfgw = np.zeros(parameters['fgw'].shape)\n",
    "    Sigw = np.zeros(parameters['igw'].shape)\n",
    "    Sogw = np.zeros(parameters['ogw'].shape)\n",
    "    Sggw = np.zeros(parameters['ggw'].shape)\n",
    "    Show = np.zeros(parameters['how'].shape)\n",
    "    \n",
    "    S = dict()\n",
    "    S['sfgw'] = Sfgw\n",
    "    S['sigw'] = Sigw\n",
    "    S['sogw'] = Sogw\n",
    "    S['sggw'] = Sggw\n",
    "    S['show'] = Show\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train(train_dataset,iters=1000,batch_size=20):\n",
    "    #initalize the parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    #initialize the V and S parameters for Adam\n",
    "    V = initialize_V(parameters)\n",
    "    S = initialize_S(parameters)\n",
    "    \n",
    "    #generate the random embeddings\n",
    "    embeddings = np.random.normal(0,0.01,(len(vocab),input_units))\n",
    "    \n",
    "    #to store the Loss, Perplexity and Accuracy for each batch\n",
    "    J = []\n",
    "    P = []\n",
    "    A = []\n",
    "    \n",
    "    \n",
    "    for step in range(iters):\n",
    "        #get batch dataset\n",
    "        index = step%len(train_dataset)\n",
    "        batches = train_dataset[index]\n",
    "        \n",
    "        #forward propagation\n",
    "        embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache = forward_propagation(batches,parameters,embeddings)\n",
    "        \n",
    "        #calculate the loss, perplexity and accuracy\n",
    "        perplexity,loss,acc = cal_loss_accuracy(batches,output_cache)\n",
    "        \n",
    "        #backward propagation\n",
    "        derivatives,embedding_error_cache = backward_propagation(batches,embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache,parameters)\n",
    "        \n",
    "        #update the parameters\n",
    "        parameters,V,S = update_parameters(parameters,derivatives,V,S,step)\n",
    "        \n",
    "        #update the embeddings\n",
    "        embeddings = update_embeddings(embeddings,embedding_error_cache,batches)\n",
    "        \n",
    "        \n",
    "        J.append(loss)\n",
    "        P.append(perplexity)\n",
    "        A.append(acc)\n",
    "        \n",
    "        #print loss, accuracy and perplexity\n",
    "        if(step%1000==0):\n",
    "            print(\"For Single Batch :\")\n",
    "            print('Step       = {}'.format(step))\n",
    "            print('Loss       = {}'.format(round(loss,2)))\n",
    "            print('Perplexity = {}'.format(round(perplexity,2)))\n",
    "            print('Accuracy   = {}'.format(round(acc*100,2)))\n",
    "            print()\n",
    "    \n",
    "    return embeddings, parameters,J,P,A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Single Batch :\n",
      "Step       = 0\n",
      "Loss       = 3117.76\n",
      "Perplexity = inf\n",
      "Accuracy   = 0.03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "embeddings,parameters,J,P,A = train(train_dataset,iters=8001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = list()\n",
    "avg_acc = list()\n",
    "avg_perp = list()\n",
    "i = 0\n",
    "while(i<len(J)):\n",
    "    avg_loss.append(np.mean(J[i:i+30]))\n",
    "    avg_acc.append(np.mean(A[i:i+30]))\n",
    "    avg_perp.append(np.mean(P[i:i+30]))\n",
    "    i += 30\n",
    "\n",
    "plt.plot(list(range(len(avg_loss))),avg_loss)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Loss (Avg of 30 batches)\")\n",
    "plt.title(\"Loss Graph\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(avg_perp))),avg_perp)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Perplexity (Avg of 30 batches)\")\n",
    "plt.title(\"Perplexity Graph\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(avg_acc))),avg_acc)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Accuracy (Avg of 30 batches)\")\n",
    "plt.title(\"Accuracy Graph\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "def predict(parameters,embeddings,id_char,vocab_size):\n",
    "    #to store some predicted names\n",
    "    names = []\n",
    "    \n",
    "    #predict 20 names\n",
    "    for i in range(20):\n",
    "        #initial activation_matrix(a0) and cell_matrix(c0)\n",
    "        a0 = np.zeros([1,hidden_units],dtype=np.float32)\n",
    "        c0 = np.zeros([1,hidden_units],dtype=np.float32)\n",
    "\n",
    "        #initalize blank name\n",
    "        name = ''\n",
    "        \n",
    "        #make a batch dataset of single char\n",
    "        batch_dataset = np.zeros([1,vocab_size])\n",
    "        \n",
    "        #get random start character\n",
    "        index = np.random.randint(0,27,1)[0]\n",
    "        \n",
    "        #make that index 1.0\n",
    "        batch_dataset[0,index] = 1.0\n",
    "        \n",
    "        #add first char to name\n",
    "        name += id_char[index]\n",
    "        \n",
    "        #get char from id_char dict\n",
    "        char = id_char[index]\n",
    "        \n",
    "        #loop until algo predicts '.'\n",
    "        while(char!='.'):\n",
    "            #get embeddings\n",
    "            batch_dataset = get_embeddings(batch_dataset,embeddings)\n",
    "\n",
    "            #lstm cell\n",
    "            lstm_activations,ct,at = lstm_cell(batch_dataset,a0,c0,parameters)\n",
    "\n",
    "            #output cell\n",
    "            ot = output_cell(at,parameters)\n",
    "            \n",
    "            #either select random.choice ot np.argmax\n",
    "            pred = np.random.choice(27,1,p=ot[0])[0]\n",
    "            \n",
    "            #get predicted char index\n",
    "            #pred = np.argmax(ot)\n",
    "                \n",
    "            #add char to name\n",
    "            name += id_char[pred]\n",
    "            \n",
    "            char = id_char[pred]\n",
    "            \n",
    "            #change the batch_dataset to this new predicted char\n",
    "            batch_dataset = np.zeros([1,vocab_size])\n",
    "            batch_dataset[0,pred] = 1.0\n",
    "\n",
    "            #update a0 and c0 to new 'at' and 'ct' for next lstm cell\n",
    "            a0 = at\n",
    "            c0 = ct\n",
    "            \n",
    "        #append the predicted name to names list\n",
    "        names.append(name)\n",
    "        \n",
    "    return names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
